{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ICW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cadspy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "from itertools import combinations\n",
    "\n",
    "# diplay all rows and cols when using 'dataframe'.head() or 'dataframe'.tail()\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icw = cadspy.DatabaseConnection(system='ICW', user='u204570')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Data\n",
    "\n",
    "#### S19 Lounge Eligibility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lounge eligibility data\n",
    "query = \"\"\"\n",
    "\n",
    "sel * from LDB_SBOX_OR.HACKATHON_OPS_LOUNGE_ELIGIBILITY\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_lounge_eligibility = icw.queryToDataframe(query)\n",
    "\n",
    "# flight info data\n",
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_FLIGHT_INFO\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_flight_info = icw.queryToDataframe(query)\n",
    "\n",
    "# country decode data\n",
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_COUNTRY_DECODE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_country = icw.queryToDataframe(query)\n",
    "\n",
    "# AC_type\n",
    "query = \"\"\"\n",
    "\n",
    "select * from LDB_SBOX_OR.HACKATHON_OPS_AC_TYPE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_acft_typ = icw.queryToDataframe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hint:* It is always worth checking the format of each of the columns in your dataframes before trying to do any work with them. To do so, you can make use of the `headers_and_first_row` function below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headers_and_first_row(df):\n",
    "    '''\n",
    "    print headers and first row of a df to deal with data types\n",
    "    '''\n",
    "    \n",
    "    headers = df.columns\n",
    "    first_row = []\n",
    "\n",
    "    for col in headers:\n",
    "        first_row.append(df[col][0])\n",
    "    \n",
    "    dictionary = dict( zip( headers, first_row) )\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "# helper function\n",
    "\n",
    "def dataframe_str_formatter(df):\n",
    "    '''Strips all whitespace in string columns in DataFrame'''\n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col][0],str):\n",
    "            df[col] = df[col].str.strip()\n",
    "        else:\n",
    "            continue\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying headers_and_first_row to df_lounge_eligibility\n",
    "format_df = headers_and_first_row(df_lounge_eligibility)\n",
    "\n",
    "# Note that some columns have blank spaces!\n",
    "format_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing code\n",
    "\n",
    "df_lounge_eligibility = dataframe_str_formatter(df_lounge_eligibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing code\n",
    "\n",
    "df_lounge_eligibility = dataframe_str_formatter(df_lounge_eligibility)\n",
    "df_lounge_eligibility['GMT_UPLIFT_DT'] = pd.to_datetime(df_lounge_eligibility['GMT_UPLIFT_DT'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_flight_info pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df = headers_and_first_row(df_flight_info)\n",
    "\n",
    "format_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing code\n",
    "\n",
    "df_flight_info = dataframe_str_formatter(df_flight_info)\n",
    "\n",
    "# Need to convert to same date type for merge\n",
    "df_flight_info['GMT_PLND_DEP_TS'] = pd.to_datetime(df_flight_info['GMT_PLND_DEP_TS'], format = '%Y-%m-%d')\n",
    "df_flight_info['GMT_PLND_DEP'] = pd.to_datetime(df_flight_info['GMT_PLND_DEP_TS'].dt.date)\n",
    "\n",
    "format_df = headers_and_first_row(df_flight_info)\n",
    "\n",
    "format_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_country pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show current format\n",
    "\n",
    "format_df_country = headers_and_first_row(df_country)\n",
    "\n",
    "format_df_country\n",
    "\n",
    "# pre-processing code\n",
    "\n",
    "df_country = dataframe_str_formatter(df_country)\n",
    "\n",
    "format_df_country = headers_and_first_row(df_country)\n",
    "\n",
    "format_df_country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df_acft_type pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show current format\n",
    "\n",
    "format_df_aircraft = headers_and_first_row(df_acft_typ)\n",
    "\n",
    "format_df_aircraft\n",
    "\n",
    "# pre-processing code\n",
    "\n",
    "df_acft_type = dataframe_str_formatter(df_acft_typ)\n",
    "\n",
    "format_df_aircraft = headers_and_first_row(df_acft_typ)\n",
    "\n",
    "format_df_aircraft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "# joining df_lounge_eligibility and df_flight_info\n",
    "\n",
    "df_lounge_elig_flight_info = pd.merge(df_lounge_eligibility,# left table\n",
    "                                     df_flight_info, # right table\n",
    "                                     left_on = ['GMT_UPLIFT_DT','OPERATING_FLT_NO','UPLIFT_STN_CD','DISCHARGE_STN_CD'], # left on? e.g. which columns from the left table are you joining on to?\n",
    "                                     right_on = ['GMT_PLND_DEP','OPG_FLT_NO','ACT_DEP_STN_CD','ACT_ARR_STN_CD'], # right on? # left on? e.g. which columns from the right table are you joining on to?\n",
    "                                     how = \"left\" # how? e.g. left, right, inner,etc\n",
    "                                     )\n",
    "\n",
    "print('Old Shape: {}'.format(df_lounge_eligibility.shape))\n",
    "print('New Shape: {}'.format(df_lounge_elig_flight_info.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Join has worked correctly by looking at some rows and countings null where join may not have worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here!\n",
    "\n",
    "df_lounge_country_flight = pd.merge(df_lounge_elig_flight_info,\n",
    "                                   df_country,\n",
    "                                   on = 'ROUTE',\n",
    "                                   how = 'left'\n",
    "                                   )\n",
    "\n",
    "print('Old Shape: {}'.format(df_lounge_elig_flight_info.shape))\n",
    "print('New Shape: {}'.format(df_lounge_country_flight.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_lounge_country_flight,\n",
    "                   df_acft_typ,\n",
    "                   on = ['IATA_AC_TYP_CD','ACT_AC_TYP_CD'],\n",
    "                   how = 'left'\n",
    "\n",
    "                   )\n",
    "\n",
    "print('Old Shape: {}'.format(df_lounge_country_flight.shape))\n",
    "print('New Shape: {}'.format(df_final.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "#\n",
    "# Your turn!!!\n",
    "#\n",
    "#--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What level of granularity do you use?</u>\n",
    "\n",
    "This project wants to understand what characteristics of a flight help us get a better picture of the lounge eligibility profiles.\n",
    "Things I want to consider:\n",
    "- Time of flight (Morning, Afternoon, Evening) or maybe even by hour\n",
    "- Destination as this determines the passenger profile, different countries/regions have more premium passengers potentially\n",
    "- Short Haul/Medium Haul/Long Haul \n",
    "- Month of Flight\n",
    "- City Route Flag\n",
    "- Weekday/Weekend \n",
    "- Business Route indicator?\n",
    "\n",
    "\n",
    "<u>General Thoughts:</u>\n",
    "\n",
    "Destination:\n",
    "- Routes are too granular as if we have new routes in the future we wouldn't be able to estimate\n",
    "- Countries could also be granular if we develop new routes to countries\n",
    "- Region may be suited as we currently fly to all regions\n",
    "- We need to think how to consider how certain countries within a region may have higher premium loads vs others\n",
    "\n",
    "<u>What metric do you use to come up with Lounge eligibility profiles?</u>\n",
    "- ... (your answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tier_proportions(features, df_fin):\n",
    "    \n",
    "    '''A function to build our the proportion of customers eligible for lounge based on features inputted'''\n",
    "\n",
    "    tier_col = 'Lounge_eligibility_tier'\n",
    "    \n",
    "    # Create group by parameters\n",
    "    groupby_list = features[:]\n",
    "    groupby_list.append(tier_col)\n",
    "\n",
    "    # Get total eligible by features and tier\n",
    "    df_grouped = df_fin.groupby(groupby_list).agg({'pax':'sum'})\n",
    "\n",
    "    # Add total amount for features excluding tier to get breakdown\n",
    "    df_grouped['total_pax_features'] = df_grouped.groupby(features)['pax'].transform('sum')\n",
    "\n",
    "    # proportion elgible \n",
    "    df_grouped['proportion'] = (df_grouped['pax'] / df_grouped['total_pax_features']) * 100\n",
    "    df_grouped['proportion'] = df_grouped['proportion'].map('{:,.1f}%'.format)\n",
    "\n",
    "    # reset index\n",
    "    df_grouped.reset_index(inplace = True)\n",
    "\n",
    "    # remove not eligible passengers\n",
    "    df_grouped = df_grouped[df_grouped[tier_col] != 'Not eligible']\n",
    "\n",
    "    # reshape data required for Ops Team\n",
    "    df = df_grouped.pivot(index = features, columns = tier_col, values = 'proportion')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Please save your final lookup table below in the form of a pandas dataframe. It must contain the categories you have come up with as rows, and the Tier 1, Tier 2, and Tier 3 percentage of costumers as columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build out the daily passengers for each flight\n",
    "\n",
    "def feature_pax_2019(features, df):\n",
    "    \n",
    "    '''Computes the passengers who travelled by features and flight number and day'''\n",
    "    \n",
    "    eval_list = features[:]\n",
    "    group_features = ['GMT_UPLIFT_DT','OPERATING_FLT_NO']\n",
    "    prop_features = group_features[:]\n",
    "    prop_features.extend(eval_list)\n",
    "    df_flight_sum = df_final.groupby(prop_features)['pax'].sum().reset_index()\n",
    "    return df_flight_sum, group_features\n",
    "    \n",
    "def proportion_formatter(df):\n",
    "    \n",
    "    '''Simple function to reformat the tier eligibility table for evaluation joins'''\n",
    "    \n",
    "    # format the proportions for the join\n",
    "    df_proportions = df.stack().reset_index()\n",
    "\n",
    "    # rename proportion column\n",
    "    df_proportions = df_proportions.rename({0:'Proportions'}, axis = 1)\n",
    "    \n",
    "    return df_proportions\n",
    "\n",
    "def flight_tier_forecast(df_prop, df_feat, feat_list):\n",
    "    \n",
    "    '''Forecasts the number of passengers in each tier for each flight'''\n",
    "    \n",
    "    # join the two\n",
    "\n",
    "    df_total = pd.merge(df_feat, df_prop, how = 'inner', on = feat_list)\n",
    "\n",
    "    # calculate proportion of each tier in each flight\n",
    "    df_total['Proportion Numeric'] = df_total['Proportions'].str.replace('%','').astype(float) / 100\n",
    "    df_total['tier_pax'] = df_total['pax'] * df_total['Proportion Numeric']\n",
    "    df_total['tier_pax'] = df_total['tier_pax'].values.round()\n",
    "\n",
    "    return df_total\n",
    "\n",
    "def eval_table(df_final, df_tot, group_features):\n",
    "\n",
    "    '''Function to create the evaluation table which compares forecast vs actual'''\n",
    "    \n",
    "    tier = 'Lounge_eligibility_tier'\n",
    "\n",
    "    tier_features = group_features[:]\n",
    "    tier_features.append(tier)\n",
    "\n",
    "    df_tier = df_final.groupby(by = tier_features)['pax'].sum().reset_index()\n",
    "    df_eval = pd.merge(df_tier, df_tot, how = 'inner', on = tier_features)\n",
    "    \n",
    "    return  df_eval\n",
    "\n",
    "def rmse(df_eval):\n",
    "    \n",
    "    '''Returns the Root Mean Squared Error of our prediction'''\n",
    "    \n",
    "    df_eval['sqrd_resid'] = (df_eval['pax_x'] - df_eval['tier_pax']) ** 2\n",
    "    std = np.sqrt(df_eval['sqrd_resid'].sum() / df_eval.shape[0])\n",
    "    \n",
    "    return std\n",
    "\n",
    "def evaluation(feat, df_fin, df_test):\n",
    "    \n",
    "    '''Function which returns the RMSE of the forecast'''\n",
    "    \n",
    "    df_feat, grp_feat = feature_pax_2019(feat, df_fin)\n",
    "    df_prop_feat = proportion_formatter(df_test)\n",
    "    df_total = flight_tier_forecast(df_prop_feat, df_feat, feat)\n",
    "    df_eval = eval_table(df_fin, df_total, grp_feat)\n",
    "    std = rmse(df_eval)\n",
    "    return std\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_evaluation(feat, df):\n",
    "    \n",
    "    df_test = tier_proportions(feat, df)\n",
    "    result = evaluation(feat, df, df_test)\n",
    "    return result\n",
    "    \n",
    "def feature_combination(features):\n",
    "    \n",
    "    '''Simple function which returns every possible combination of features'''\n",
    "    \n",
    "    nbr_features = len(features)\n",
    "    feature_comb_list = []\n",
    "    for nbr in range(1,nbr_features + 1):\n",
    "        stage_comb = [list(comb) for comb in combinations(features, nbr)]\n",
    "        feature_comb_list.extend(stage_comb)\n",
    "        \n",
    "    return feature_comb_list\n",
    "    \n",
    "def combination_evaluation(features, df):\n",
    "    \n",
    "    '''A function to test every combination and evaluate its performance'''\n",
    "    \n",
    "    results = []\n",
    "    test_features = feature_combination(features)\n",
    "    \n",
    "    # loop through every combination of features and test result\n",
    "    for feat_comb in test_features:\n",
    "        rmse = feature_evaluation(feat_comb, df)\n",
    "        results.append([feat_comb,rmse])\n",
    "        \n",
    "    # create dataframe of results\n",
    "    df_result = pd.DataFrame(results, columns = ['feature_combination','RMSE'])\n",
    "    df_result = df_result.sort_values('RMSE', ascending = True)\n",
    "    \n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['CORP_GEOG_CTRY_GRP_NM_x', 'WB_NB_CAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = combination_evaluation(features, df_final)\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5d.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "lcc_arn": "arn:aws:sagemaker:eu-west-1:954353547965:studio-lifecycle-config/install-cadspy-v1-8-1r2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
